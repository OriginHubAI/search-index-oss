// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: histogram.proto

#include "histogram.pb.h"

#include <algorithm>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
#include "google/protobuf/generated_message_tctable_impl.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace tensorflow {

inline constexpr HistogramProto::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : bucket_limit_{},
        bucket_{},
        min_{0},
        max_{0},
        num_{0},
        sum_{0},
        sum_squares_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR HistogramProto::HistogramProto(::_pbi::ConstantInitialized)
    : _impl_(::_pbi::ConstantInitialized()) {}
struct HistogramProtoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR HistogramProtoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~HistogramProtoDefaultTypeInternal() {}
  union {
    HistogramProto _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 HistogramProtoDefaultTypeInternal _HistogramProto_default_instance_;
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_histogram_2eproto[1];
static constexpr const ::_pb::EnumDescriptor**
    file_level_enum_descriptors_histogram_2eproto = nullptr;
static constexpr const ::_pb::ServiceDescriptor**
    file_level_service_descriptors_histogram_2eproto = nullptr;
const ::uint32_t TableStruct_histogram_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(
    protodesc_cold) = {
    ~0u,  // no _has_bits_
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    ~0u,  // no _weak_field_map_
    ~0u,  // no _inlined_string_donated_
    ~0u,  // no _split_
    ~0u,  // no sizeof(Split)
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.min_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.max_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.num_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.sum_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.sum_squares_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.bucket_limit_),
    PROTOBUF_FIELD_OFFSET(::tensorflow::HistogramProto, _impl_.bucket_),
};

static const ::_pbi::MigrationSchema
    schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
        {0, -1, -1, sizeof(::tensorflow::HistogramProto)},
};

static const ::_pb::Message* const file_default_instances[] = {
    &::tensorflow::_HistogramProto_default_instance_._instance,
};
const char descriptor_table_protodef_histogram_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
    "\n\017histogram.proto\022\ntensorflow\"\207\001\n\016Histog"
    "ramProto\022\013\n\003min\030\001 \001(\001\022\013\n\003max\030\002 \001(\001\022\013\n\003nu"
    "m\030\003 \001(\001\022\013\n\003sum\030\004 \001(\001\022\023\n\013sum_squares\030\005 \001("
    "\001\022\030\n\014bucket_limit\030\006 \003(\001B\002\020\001\022\022\n\006bucket\030\007 "
    "\003(\001B\002\020\001B\\\n\030org.tensorflow.frameworkP\001Z;g"
    "ithub.com/google/tsl/tsl/go/core/protobu"
    "f/summary_go_proto\370\001\001b\006proto3"
};
static ::absl::once_flag descriptor_table_histogram_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_histogram_2eproto = {
    false,
    false,
    269,
    descriptor_table_protodef_histogram_2eproto,
    "histogram.proto",
    &descriptor_table_histogram_2eproto_once,
    nullptr,
    0,
    1,
    schemas,
    file_default_instances,
    TableStruct_histogram_2eproto::offsets,
    file_level_metadata_histogram_2eproto,
    file_level_enum_descriptors_histogram_2eproto,
    file_level_service_descriptors_histogram_2eproto,
};

// This function exists to be marked as weak.
// It can significantly speed up compilation by breaking up LLVM's SCC
// in the .pb.cc translation units. Large translation units see a
// reduction of more than 35% of walltime for optimized builds. Without
// the weak attribute all the messages in the file, including all the
// vtables and everything they use become part of the same SCC through
// a cycle like:
// GetMetadata -> descriptor table -> default instances ->
//   vtables -> GetMetadata
// By adding a weak function here we break the connection from the
// individual vtables back into the descriptor table.
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_histogram_2eproto_getter() {
  return &descriptor_table_histogram_2eproto;
}
// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2
static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_histogram_2eproto(&descriptor_table_histogram_2eproto);
namespace tensorflow {
// ===================================================================

class HistogramProto::_Internal {
 public:
};

HistogramProto::HistogramProto(::google::protobuf::Arena* arena)
    : ::google::protobuf::Message(arena) {
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.HistogramProto)
}
inline PROTOBUF_NDEBUG_INLINE HistogramProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from)
      : bucket_limit_{visibility, arena, from.bucket_limit_},
        bucket_{visibility, arena, from.bucket_},
        _cached_size_{0} {}

HistogramProto::HistogramProto(
    ::google::protobuf::Arena* arena,
    const HistogramProto& from)
    : ::google::protobuf::Message(arena) {
  HistogramProto* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, min_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, min_),
           offsetof(Impl_, sum_squares_) -
               offsetof(Impl_, min_) +
               sizeof(Impl_::sum_squares_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.HistogramProto)
}
inline PROTOBUF_NDEBUG_INLINE HistogramProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : bucket_limit_{visibility, arena},
        bucket_{visibility, arena},
        _cached_size_{0} {}

inline void HistogramProto::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, min_),
           0,
           offsetof(Impl_, sum_squares_) -
               offsetof(Impl_, min_) +
               sizeof(Impl_::sum_squares_));
}
HistogramProto::~HistogramProto() {
  // @@protoc_insertion_point(destructor:tensorflow.HistogramProto)
  _internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  SharedDtor();
}
inline void HistogramProto::SharedDtor() {
  ABSL_DCHECK(GetArena() == nullptr);
  _impl_.~Impl_();
}

PROTOBUF_NOINLINE void HistogramProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.HistogramProto)
  PROTOBUF_TSAN_WRITE(&_impl_._tsan_detect_race);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.bucket_limit_.Clear();
  _impl_.bucket_.Clear();
  ::memset(&_impl_.min_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.sum_squares_) -
      reinterpret_cast<char*>(&_impl_.min_)) + sizeof(_impl_.sum_squares_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

const char* HistogramProto::_InternalParse(
    const char* ptr, ::_pbi::ParseContext* ctx) {
  ptr = ::_pbi::TcParser::ParseLoop(this, ptr, ctx, &_table_.header);
  return ptr;
}


PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 7, 0, 0, 2> HistogramProto::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    7, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967168,  // skipmap
    offsetof(decltype(_table_), field_entries),
    7,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    &_HistogramProto_default_instance_._instance,
    ::_pbi::TcParser::GenericFallback,  // fallback
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // double min = 1;
    {::_pbi::TcParser::FastF64S1,
     {9, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.min_)}},
    // double max = 2;
    {::_pbi::TcParser::FastF64S1,
     {17, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.max_)}},
    // double num = 3;
    {::_pbi::TcParser::FastF64S1,
     {25, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.num_)}},
    // double sum = 4;
    {::_pbi::TcParser::FastF64S1,
     {33, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.sum_)}},
    // double sum_squares = 5;
    {::_pbi::TcParser::FastF64S1,
     {41, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.sum_squares_)}},
    // repeated double bucket_limit = 6 [packed = true];
    {::_pbi::TcParser::FastF64P1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.bucket_limit_)}},
    // repeated double bucket = 7 [packed = true];
    {::_pbi::TcParser::FastF64P1,
     {58, 63, 0, PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.bucket_)}},
  }}, {{
    65535, 65535
  }}, {{
    // double min = 1;
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.min_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // double max = 2;
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.max_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // double num = 3;
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.num_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // double sum = 4;
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.sum_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // double sum_squares = 5;
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.sum_squares_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // repeated double bucket_limit = 6 [packed = true];
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.bucket_limit_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedDouble)},
    // repeated double bucket = 7 [packed = true];
    {PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.bucket_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedDouble)},
  }},
  // no aux_entries
  {{
  }},
};

::uint8_t* HistogramProto::_InternalSerialize(
    ::uint8_t* target,
    ::google::protobuf::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.HistogramProto)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // double min = 1;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_min = this->_internal_min();
  ::uint64_t raw_min;
  memcpy(&raw_min, &tmp_min, sizeof(tmp_min));
  if (raw_min != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(
        1, this->_internal_min(), target);
  }

  // double max = 2;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_max = this->_internal_max();
  ::uint64_t raw_max;
  memcpy(&raw_max, &tmp_max, sizeof(tmp_max));
  if (raw_max != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(
        2, this->_internal_max(), target);
  }

  // double num = 3;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_num = this->_internal_num();
  ::uint64_t raw_num;
  memcpy(&raw_num, &tmp_num, sizeof(tmp_num));
  if (raw_num != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(
        3, this->_internal_num(), target);
  }

  // double sum = 4;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum = this->_internal_sum();
  ::uint64_t raw_sum;
  memcpy(&raw_sum, &tmp_sum, sizeof(tmp_sum));
  if (raw_sum != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(
        4, this->_internal_sum(), target);
  }

  // double sum_squares = 5;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum_squares = this->_internal_sum_squares();
  ::uint64_t raw_sum_squares;
  memcpy(&raw_sum_squares, &tmp_sum_squares, sizeof(tmp_sum_squares));
  if (raw_sum_squares != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(
        5, this->_internal_sum_squares(), target);
  }

  // repeated double bucket_limit = 6 [packed = true];
  if (this->_internal_bucket_limit_size() > 0) {
    target = stream->WriteFixedPacked(6, _internal_bucket_limit(), target);
  }

  // repeated double bucket = 7 [packed = true];
  if (this->_internal_bucket_size() > 0) {
    target = stream->WriteFixedPacked(7, _internal_bucket(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.HistogramProto)
  return target;
}

::size_t HistogramProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.HistogramProto)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated double bucket_limit = 6 [packed = true];
  {
    std::size_t data_size = std::size_t{8} *
        ::_pbi::FromIntSize(this->_internal_bucket_limit_size())
    ;
    std::size_t tag_size = data_size == 0
        ? 0
        : 1 + ::_pbi::WireFormatLite::Int32Size(
                            static_cast<int32_t>(data_size))
    ;
    total_size += tag_size + data_size;
  }
  // repeated double bucket = 7 [packed = true];
  {
    std::size_t data_size = std::size_t{8} *
        ::_pbi::FromIntSize(this->_internal_bucket_size())
    ;
    std::size_t tag_size = data_size == 0
        ? 0
        : 1 + ::_pbi::WireFormatLite::Int32Size(
                            static_cast<int32_t>(data_size))
    ;
    total_size += tag_size + data_size;
  }
  // double min = 1;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_min = this->_internal_min();
  ::uint64_t raw_min;
  memcpy(&raw_min, &tmp_min, sizeof(tmp_min));
  if (raw_min != 0) {
    total_size += 9;
  }

  // double max = 2;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_max = this->_internal_max();
  ::uint64_t raw_max;
  memcpy(&raw_max, &tmp_max, sizeof(tmp_max));
  if (raw_max != 0) {
    total_size += 9;
  }

  // double num = 3;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_num = this->_internal_num();
  ::uint64_t raw_num;
  memcpy(&raw_num, &tmp_num, sizeof(tmp_num));
  if (raw_num != 0) {
    total_size += 9;
  }

  // double sum = 4;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum = this->_internal_sum();
  ::uint64_t raw_sum;
  memcpy(&raw_sum, &tmp_sum, sizeof(tmp_sum));
  if (raw_sum != 0) {
    total_size += 9;
  }

  // double sum_squares = 5;
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum_squares = this->_internal_sum_squares();
  ::uint64_t raw_sum_squares;
  memcpy(&raw_sum_squares, &tmp_sum_squares, sizeof(tmp_sum_squares));
  if (raw_sum_squares != 0) {
    total_size += 9;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::google::protobuf::Message::ClassData HistogramProto::_class_data_ = {
    HistogramProto::MergeImpl,
    nullptr,  // OnDemandRegisterArenaDtor
};
const ::google::protobuf::Message::ClassData* HistogramProto::GetClassData() const {
  return &_class_data_;
}

void HistogramProto::MergeImpl(::google::protobuf::Message& to_msg, const ::google::protobuf::Message& from_msg) {
  auto* const _this = static_cast<HistogramProto*>(&to_msg);
  auto& from = static_cast<const HistogramProto&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.HistogramProto)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_bucket_limit()->MergeFrom(from._internal_bucket_limit());
  _this->_internal_mutable_bucket()->MergeFrom(from._internal_bucket());
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_min = from._internal_min();
  ::uint64_t raw_min;
  memcpy(&raw_min, &tmp_min, sizeof(tmp_min));
  if (raw_min != 0) {
    _this->_internal_set_min(from._internal_min());
  }
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_max = from._internal_max();
  ::uint64_t raw_max;
  memcpy(&raw_max, &tmp_max, sizeof(tmp_max));
  if (raw_max != 0) {
    _this->_internal_set_max(from._internal_max());
  }
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_num = from._internal_num();
  ::uint64_t raw_num;
  memcpy(&raw_num, &tmp_num, sizeof(tmp_num));
  if (raw_num != 0) {
    _this->_internal_set_num(from._internal_num());
  }
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum = from._internal_sum();
  ::uint64_t raw_sum;
  memcpy(&raw_sum, &tmp_sum, sizeof(tmp_sum));
  if (raw_sum != 0) {
    _this->_internal_set_sum(from._internal_sum());
  }
  static_assert(sizeof(::uint64_t) == sizeof(double),
                "Code assumes ::uint64_t and double are the same size.");
  double tmp_sum_squares = from._internal_sum_squares();
  ::uint64_t raw_sum_squares;
  memcpy(&raw_sum_squares, &tmp_sum_squares, sizeof(tmp_sum_squares));
  if (raw_sum_squares != 0) {
    _this->_internal_set_sum_squares(from._internal_sum_squares());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void HistogramProto::CopyFrom(const HistogramProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.HistogramProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

PROTOBUF_NOINLINE bool HistogramProto::IsInitialized() const {
  return true;
}

::_pbi::CachedSize* HistogramProto::AccessCachedSize() const {
  return &_impl_._cached_size_;
}
void HistogramProto::InternalSwap(HistogramProto* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.bucket_limit_.InternalSwap(&other->_impl_.bucket_limit_);
  _impl_.bucket_.InternalSwap(&other->_impl_.bucket_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.sum_squares_)
      + sizeof(HistogramProto::_impl_.sum_squares_)
      - PROTOBUF_FIELD_OFFSET(HistogramProto, _impl_.min_)>(
          reinterpret_cast<char*>(&_impl_.min_),
          reinterpret_cast<char*>(&other->_impl_.min_));
}

::google::protobuf::Metadata HistogramProto::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_histogram_2eproto_getter, &descriptor_table_histogram_2eproto_once,
      file_level_metadata_histogram_2eproto[0]);
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
#include "google/protobuf/port_undef.inc"
